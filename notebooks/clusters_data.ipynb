{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "40b32c0c",
   "metadata": {},
   "source": [
    "# Cluster Data Extraction\n",
    "\n",
    "Processes all LArIAT events to extract clusters from connected regions in both collection and induction planes. Creates a structured dataset where each cluster becomes a data point with properties like area, intensity, geometry, and transformed matrices for analysis.\n",
    "\n",
    "**Output:** DataFrame with cluster features for machine learning and physics analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "1112f8a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "8aae9e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import uproot\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import awkward as ak\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from skimage.measure import label, regionprops\n",
    "from scipy.ndimage import label as scipy_label\n",
    "from collections import deque\n",
    "\n",
    "from lariat import Event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b6e64704",
   "metadata": {},
   "outputs": [],
   "source": [
    "deuterons = pd.read_csv('/Users/user/data/research/proton-deuteron/csv/deuteron_candidates_bbox_t100.csv') # from within vertices bounding box\n",
    "protons = pd.read_csv('/Users/user/data/research/proton-deuteron/csv/protons_one_track_filepaths.csv') # with only one track from reco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "681e13bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_all_clusters_to_df(events_df, particle_type, threshold=15, max_events=None):\n",
    "    \"\"\"Extract all clusters from events and create a pandas dataframe\"\"\"\n",
    "    \n",
    "    cluster_data = []\n",
    "    \n",
    "    # Limit events if specified\n",
    "    if max_events:\n",
    "        events_df = events_df.head(max_events)\n",
    "    \n",
    "    for i, row in events_df.iterrows(): # iterrows gives index, Series (row)\n",
    "        try:\n",
    "            # Create event\n",
    "            event = Event(row.file_path, index=row.event_index)\n",
    "            \n",
    "            # Get connected regions for collection plane\n",
    "            clabeled, cregions = event.connectedregions(event.collection, threshold=threshold)\n",
    "            ilabeled, iregions = event.connectedregions(event.induction, threshold=threshold)\n",
    "            \n",
    "            # Process collection plane clusters\n",
    "            if cregions is not None:\n",
    "                for j, region in enumerate(cregions): # index, element \n",
    "\n",
    "                    matrix = region.image_intensity \n",
    "                    matrix_transformed = matrix.T[::-1] # image of cluster \n",
    "                    column_maxes = np.max(matrix_transformed, axis=0) # 1D matrix, max ADC for each wire in cluster - gives a 1D view of energy deposition\n",
    "                    \n",
    "                    cluster_info = {\n",
    "                        'event_idx': i,\n",
    "                        'run': row.run,\n",
    "                        'subrun': row.subrun,\n",
    "                        'event': row.event,\n",
    "                        'file_path': row.file_path,\n",
    "                        'event_index': row.event_index,\n",
    "                        'particle_type': particle_type,\n",
    "                        'plane': 'collection',\n",
    "                        'cluster_idx': j,\n",
    "                        'area': region.area,\n",
    "                        'max_intensity': region.intensity_max,\n",
    "                        'min_intensity': region.intensity_min,\n",
    "                        'mean_intensity': region.intensity_mean,\n",
    "                        'total_intensity': region.intensity_image.sum(),\n",
    "                        'centroid_x': region.centroid[0],\n",
    "                        'centroid_y': region.centroid[1],\n",
    "                        'bbox_min_row': region.bbox[0],\n",
    "                        'bbox_min_col': region.bbox[1],\n",
    "                        'bbox_max_row': region.bbox[2],\n",
    "                        'bbox_max_col': region.bbox[3],\n",
    "                        'width': region.bbox[3] - region.bbox[1],\n",
    "                        'height': region.bbox[2] - region.bbox[0],\n",
    "                        'aspect_ratio': (region.bbox[3] - region.bbox[1]) / (region.bbox[2] - region.bbox[0]),\n",
    "                        'compactness': region.area / ((region.bbox[3] - region.bbox[1]) * (region.bbox[2] - region.bbox[0])),\n",
    "                        'image_intensity': region.image_intensity,  # Original image\n",
    "                        'matrix_transformed': matrix_transformed,   # Transposed and flipped matrix\n",
    "                        'column_maxes': column_maxes               # Column maxes array\n",
    "                    }\n",
    "                    cluster_data.append(cluster_info)\n",
    "            \n",
    "            # Process induction plane clusters\n",
    "            if iregions is not None:\n",
    "                for j, region in enumerate(iregions):\n",
    "                    # Get the matrix and column maxes\n",
    "                    matrix = region.image_intensity\n",
    "                    matrix_transformed = matrix.T[::-1]\n",
    "                    column_maxes = np.max(matrix_transformed, axis=0)\n",
    "                    \n",
    "                    cluster_info = {\n",
    "                        'event_idx': i,\n",
    "                        'run': row.run,\n",
    "                        'subrun': row.subrun,\n",
    "                        'event': row.event,\n",
    "                        'file_path': row.file_path,\n",
    "                        'event_index': row.event_index,\n",
    "                        'particle_type': particle_type,\n",
    "                        'plane': 'induction',\n",
    "                        'cluster_idx': j,\n",
    "                        'area': region.area,\n",
    "                        'max_intensity': region.intensity_max,\n",
    "                        'min_intensity': region.intensity_min,\n",
    "                        'mean_intensity': region.intensity_mean,\n",
    "                        'total_intensity': region.intensity_image.sum(),\n",
    "                        'centroid_x': region.centroid[0],\n",
    "                        'centroid_y': region.centroid[1],\n",
    "                        'bbox_min_row': region.bbox[0],\n",
    "                        'bbox_min_col': region.bbox[1],\n",
    "                        'bbox_max_row': region.bbox[2],\n",
    "                        'bbox_max_col': region.bbox[3],\n",
    "                        'width': region.bbox[3] - region.bbox[1],\n",
    "                        'height': region.bbox[2] - region.bbox[0],\n",
    "                        'aspect_ratio': (region.bbox[3] - region.bbox[1]) / (region.bbox[2] - region.bbox[0]),\n",
    "                        'compactness': region.area / ((region.bbox[3] - region.bbox[1]) * (region.bbox[2] - region.bbox[0])),\n",
    "                        'image_intensity': region.image_intensity,  # Original image\n",
    "                        'matrix_transformed': matrix_transformed,   # Transposed and flipped matrix\n",
    "                        'column_maxes': column_maxes               # Column maxes array\n",
    "                    }\n",
    "                    cluster_data.append(cluster_info)\n",
    "                    \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing event {i}: {e}\")\n",
    "            continue\n",
    "    \n",
    "    return pd.DataFrame(cluster_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9746b50e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# deuteron_clusters_df = extract_all_clusters_to_df(deuterons, 'deuteron', threshold=15)\n",
    "\n",
    "# proton_clusters_df = extract_all_clusters_to_df(protons, 'proton', threshold=15)\n",
    "\n",
    "# all_clusters_df = pd.concat([deuteron_clusters_df, proton_clusters_df], ignore_index=True)\n",
    "\n",
    "# all_clusters_df.to_pickle('/Users/user/data/research/proton-deuteron/csv/all_clusters_df.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
